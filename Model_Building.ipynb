{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a779f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "863ac467",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies_scaled = pd.read_csv(\"preprocessed_data.csv\")\n",
    "all_data = pd.read_csv(\"all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2831e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 1].drop(['train_test'], axis =1)\n",
    "X_test_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 0].drop(['train_test'], axis =1)\n",
    "\n",
    "y_train = all_data[all_data.train_test==1].Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0cd28",
   "metadata": {},
   "source": [
    "# Model Building (Baseline Validation Performance)Â¶\n",
    "\n",
    "Before going further, I like to see how various different models perform with default parameters. I tried the following models using 5 fold cross validation to get a baseline. With a validation set basline, we can see how much tuning improves each of the models. Just because a model has a high basline on this validation set doesn't mean that it will actually do better on the eventual test set.\n",
    "\n",
    "## Naive Bayes (75.3%)\n",
    "## Logistic Regression (82.0%)\n",
    "## Decision Tree (76.2%)\n",
    "## K Nearest Neighbor (50.2%)\n",
    "## Random Forest (81.5%)\n",
    "## Support Vector Classifier (61.7%)\n",
    "## Soft Voting Classifier - All Models (77.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "233d3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e28bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70224719 0.73595506 0.78089888 0.76404494 0.77966102]\n",
      "0.7525614168729766\n"
     ]
    }
   ],
   "source": [
    "#I usually use Naive Bayes as a baseline for my classification tasks \n",
    "\n",
    "gnb = GaussianNB()\n",
    "cv = cross_val_score(gnb,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ca12d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81460674 0.80898876 0.80337079 0.82022472 0.85310734]\n",
      "0.8200596711737447\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression( max_iter=1000)\n",
    "cv = cross_val_score(lr,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed53cc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62359551 0.79775281 0.80337079 0.78651685 0.83615819]\n",
      "0.7694788294293151\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "cv = cross_val_score(dt,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15798700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61797753 0.38202247 0.46067416 0.43258427 0.61581921]\n",
      "0.5018155272011681\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bf0effb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80337079 0.79213483 0.8258427  0.78089888 0.84180791]\n",
      "0.8088110201231512\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "cv = cross_val_score(rf,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c728bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61797753 0.61797753 0.61797753 0.61797753 0.61581921]\n",
      "0.6175458642798197\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability=True)\n",
    "cv = cross_val_score(svc,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23f31820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7247191  0.78089888 0.79213483 0.78089888 0.80225989]\n",
      "0.7761823144797816\n"
     ]
    }
   ],
   "source": [
    "#Voting classifier takes all of the inputs and averages the results. For a \"hard\" voting classifier each classifier gets 1 vote \"yes\" or \"no\" and the result is just a popular vote. For this, you generally want odd numbers\n",
    "#A \"soft\" classifier averages the confidence of each of the models. If a the average confidence is > 50% that it is a 1 it will be counted as such\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),\n",
    "                                            ('svc',svc)], voting = 'soft')\n",
    "cv = cross_val_score(voting_clf,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
